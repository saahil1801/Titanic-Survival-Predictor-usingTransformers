{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import (\n    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, \n    BaggingClassifier, VotingClassifier , RandomForestRegressor\n)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import RandomOverSampler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-04T08:48:19.332828Z","iopub.execute_input":"2023-10-04T08:48:19.333821Z","iopub.status.idle":"2023-10-04T08:48:20.761540Z","shell.execute_reply.started":"2023-10-04T08:48:19.333779Z","shell.execute_reply":"2023-10-04T08:48:20.760478Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import re","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.764091Z","iopub.execute_input":"2023-10-04T08:48:20.764578Z","iopub.status.idle":"2023-10-04T08:48:20.770073Z","shell.execute_reply.started":"2023-10-04T08:48:20.764538Z","shell.execute_reply":"2023-10-04T08:48:20.768529Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/titanic/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.771691Z","iopub.execute_input":"2023-10-04T08:48:20.772566Z","iopub.status.idle":"2023-10-04T08:48:20.815499Z","shell.execute_reply.started":"2023-10-04T08:48:20.772532Z","shell.execute_reply":"2023-10-04T08:48:20.814309Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df['Survived'].value_counts() #predict this target variable \n#display the number of occurrences of each unique value in the 'Survived' column","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.817965Z","iopub.execute_input":"2023-10-04T08:48:20.818341Z","iopub.status.idle":"2023-10-04T08:48:20.835167Z","shell.execute_reply.started":"2023-10-04T08:48:20.818309Z","shell.execute_reply":"2023-10-04T08:48:20.833936Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0    549\n1    342\nName: Survived, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.836636Z","iopub.execute_input":"2023-10-04T08:48:20.837697Z","iopub.status.idle":"2023-10-04T08:48:20.870977Z","shell.execute_reply.started":"2023-10-04T08:48:20.837660Z","shell.execute_reply":"2023-10-04T08:48:20.870178Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['Pclass'].value_counts() \n#display the number of occurrences of each unique value in the 'Pclass' column","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.872402Z","iopub.execute_input":"2023-10-04T08:48:20.873460Z","iopub.status.idle":"2023-10-04T08:48:20.879965Z","shell.execute_reply.started":"2023-10-04T08:48:20.873426Z","shell.execute_reply":"2023-10-04T08:48:20.879194Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"3    491\n1    216\n2    184\nName: Pclass, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.shape #dimensionality of the dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.881456Z","iopub.execute_input":"2023-10-04T08:48:20.881991Z","iopub.status.idle":"2023-10-04T08:48:20.894229Z","shell.execute_reply.started":"2023-10-04T08:48:20.881950Z","shell.execute_reply":"2023-10-04T08:48:20.893426Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(891, 12)"},"metadata":{}}]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.895366Z","iopub.execute_input":"2023-10-04T08:48:20.895848Z","iopub.status.idle":"2023-10-04T08:48:20.908925Z","shell.execute_reply.started":"2023-10-04T08:48:20.895819Z","shell.execute_reply":"2023-10-04T08:48:20.907627Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"PassengerId      int64\nSurvived         int64\nPclass           int64\nName            object\nSex             object\nAge            float64\nSibSp            int64\nParch            int64\nTicket          object\nFare           float64\nCabin           object\nEmbarked        object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.910808Z","iopub.execute_input":"2023-10-04T08:48:20.911278Z","iopub.status.idle":"2023-10-04T08:48:20.926184Z","shell.execute_reply.started":"2023-10-04T08:48:20.911235Z","shell.execute_reply":"2023-10-04T08:48:20.924857Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df['FamilySize'] = df['SibSp'] + df['Parch']\n#calculates a new column 'FamilySize' in the DataFrame df by adding the values of 'SibSp' (number of siblings/spouses) and 'Parch' (number of parents/children).\n\ndf = df.drop(columns=['SibSp', 'Parch']) \n#dremoves the 'SibSp' and 'Parch' columns from the DataFrame df, \n#effectively dropping these columns from the dataset.","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.930529Z","iopub.execute_input":"2023-10-04T08:48:20.931268Z","iopub.status.idle":"2023-10-04T08:48:20.941575Z","shell.execute_reply.started":"2023-10-04T08:48:20.931225Z","shell.execute_reply":"2023-10-04T08:48:20.940331Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=['Name', 'Ticket','PassengerId'])\n#removes the 'Name', 'Ticket', and 'PassengerId' columns from the DataFrame df, effectively dropping these columns from the dataset.\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.942916Z","iopub.execute_input":"2023-10-04T08:48:20.943768Z","iopub.status.idle":"2023-10-04T08:48:20.957626Z","shell.execute_reply.started":"2023-10-04T08:48:20.943728Z","shell.execute_reply":"2023-10-04T08:48:20.956403Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df['FamilySize'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.959235Z","iopub.execute_input":"2023-10-04T08:48:20.959650Z","iopub.status.idle":"2023-10-04T08:48:20.974259Z","shell.execute_reply.started":"2023-10-04T08:48:20.959619Z","shell.execute_reply":"2023-10-04T08:48:20.972535Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0     537\n1     161\n2     102\n3      29\n5      22\n4      15\n6      12\n10      7\n7       6\nName: FamilySize, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}#creates a dictionary named deck that maps deck letters (A, B, C, etc.) to numerical values.\n\ndf['Cabin'] =df['Cabin'].fillna(\"U0\")#It fills missing values in the 'Cabin' column with \"U0\" (indicating an unknown or unspecified deck level).\n\ndf['Deck'] = df['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n\n#This above line extracts the alphabetic characters (deck letters) from each 'Cabin' entry using a regular expression and stores them in a new 'Deck' column.\n\ndf['Deck'] = df['Deck'].map(deck)\n#It maps the extracted deck letters to their corresponding numerical values using the deck dictionary defined earlier.\n\ndf['Deck'] = df['Deck'].fillna(0) #It fills any remaining missing values in the 'Deck' column with 0.\ndf['Deck'] = df['Deck'].astype(int) #This line converts the 'Deck' column to integers to ensure it contains numerical data.\n\n# we can now drop the cabin feature\ndf = df.drop(columns=['Cabin'])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:20.975853Z","iopub.execute_input":"2023-10-04T08:48:20.976678Z","iopub.status.idle":"2023-10-04T08:48:20.998714Z","shell.execute_reply.started":"2023-10-04T08:48:20.976632Z","shell.execute_reply":"2023-10-04T08:48:20.997315Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"features = [ 'Age','Fare', 'Sex','Deck','Pclass', 'FamilySize','Embarked']\n#Features that are important and that we will be working on","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.000132Z","iopub.execute_input":"2023-10-04T08:48:21.000517Z","iopub.status.idle":"2023-10-04T08:48:21.013641Z","shell.execute_reply.started":"2023-10-04T08:48:21.000485Z","shell.execute_reply":"2023-10-04T08:48:21.012604Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Define a pipeline for numerical features, including imputation with mean and standard scaling\nnum_features = ['Age', 'Fare']\nnum_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n    ('scaler', StandardScaler())  # Scale the features using StandardScaler\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.014731Z","iopub.execute_input":"2023-10-04T08:48:21.015477Z","iopub.status.idle":"2023-10-04T08:48:21.025867Z","shell.execute_reply.started":"2023-10-04T08:48:21.015442Z","shell.execute_reply":"2023-10-04T08:48:21.024858Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Defined a pipeline for categorical features, including imputation with the most frequent value and one-hot encoding\ncat_features = ['Sex', 'Deck', 'Pclass', 'FamilySize', 'Embarked']\ncat_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputed missing values with the most frequent value\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # Performed one-hot encoding, ignoring unknown categories\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.027074Z","iopub.execute_input":"2023-10-04T08:48:21.027432Z","iopub.status.idle":"2023-10-04T08:48:21.039321Z","shell.execute_reply.started":"2023-10-04T08:48:21.027404Z","shell.execute_reply":"2023-10-04T08:48:21.038222Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Defined a ColumnTransformer to apply specific transformations to numerical and categorical features\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', num_transformer, num_features),  # Applied numerical transformation to 'num_features'\n        ('cat', cat_transformer, cat_features)  # Appled categorical transformation to 'cat_features'\n    ])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.040668Z","iopub.execute_input":"2023-10-04T08:48:21.041579Z","iopub.status.idle":"2023-10-04T08:48:21.051032Z","shell.execute_reply.started":"2023-10-04T08:48:21.041547Z","shell.execute_reply":"2023-10-04T08:48:21.050225Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Used the preprocessor to transform the selected features and target variable\nX = preprocessor.fit_transform(df[features])  # Transformed the features\ny = df['Survived']  # Defined the target variable 'Survived'\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.052320Z","iopub.execute_input":"2023-10-04T08:48:21.053580Z","iopub.status.idle":"2023-10-04T08:48:21.086470Z","shell.execute_reply.started":"2023-10-04T08:48:21.053538Z","shell.execute_reply":"2023-10-04T08:48:21.085577Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Used the preprocessor to access the 'cat' transformer and 'encoder'\nencoder = preprocessor.named_transformers_['cat']['encoder']\n\n# Obtained the encoded feature names and combined them with numerical feature names\nencoded_feature_names1 = list(encoder.get_feature_names_out(cat_features))\ncolumn_names = num_features + encoded_feature_names1\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:50:16.082099Z","iopub.execute_input":"2023-10-04T08:50:16.082514Z","iopub.status.idle":"2023-10-04T08:50:16.088478Z","shell.execute_reply.started":"2023-10-04T08:50:16.082477Z","shell.execute_reply":"2023-10-04T08:50:16.087243Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"column_names","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:50:17.978978Z","iopub.execute_input":"2023-10-04T08:50:17.980017Z","iopub.status.idle":"2023-10-04T08:50:17.986739Z","shell.execute_reply.started":"2023-10-04T08:50:17.979972Z","shell.execute_reply":"2023-10-04T08:50:17.985866Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"['Age',\n 'Fare',\n 'Sex_female',\n 'Sex_male',\n 'Deck_0',\n 'Deck_1',\n 'Deck_2',\n 'Deck_3',\n 'Deck_4',\n 'Deck_5',\n 'Deck_6',\n 'Deck_7',\n 'Deck_8',\n 'Pclass_1',\n 'Pclass_2',\n 'Pclass_3',\n 'FamilySize_0',\n 'FamilySize_1',\n 'FamilySize_2',\n 'FamilySize_3',\n 'FamilySize_4',\n 'FamilySize_5',\n 'FamilySize_6',\n 'FamilySize_7',\n 'FamilySize_10',\n 'Embarked_C',\n 'Embarked_Q',\n 'Embarked_S']"},"metadata":{}}]},{"cell_type":"code","source":"# Transformed the sparse array 'X' to a DataFrame with column names 'column_names'\nX = pd.DataFrame(X.toarray(), columns=column_names)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.113195Z","iopub.execute_input":"2023-10-04T08:48:21.113892Z","iopub.status.idle":"2023-10-04T08:48:21.125038Z","shell.execute_reply.started":"2023-10-04T08:48:21.113862Z","shell.execute_reply":"2023-10-04T08:48:21.123736Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Applied random oversampling to address class imbalance\noversampler = RandomOverSampler(random_state=42)\n\n# Resampled the feature and target variables 'X' and 'y'\nX_resampled, y_resampled = oversampler.fit_resample(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.126860Z","iopub.execute_input":"2023-10-04T08:48:21.127275Z","iopub.status.idle":"2023-10-04T08:48:21.141907Z","shell.execute_reply.started":"2023-10-04T08:48:21.127242Z","shell.execute_reply":"2023-10-04T08:48:21.140793Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.143292Z","iopub.execute_input":"2023-10-04T08:48:21.143902Z","iopub.status.idle":"2023-10-04T08:48:21.151441Z","shell.execute_reply.started":"2023-10-04T08:48:21.143873Z","shell.execute_reply":"2023-10-04T08:48:21.150307Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Created multiple classification models and a voting classifier\nrandom_forest_clf = RandomForestClassifier(random_state=42)\ngradient_boosting_clf = GradientBoostingClassifier(random_state=42)\nada_boost_clf = AdaBoostClassifier(random_state=42)\nsvc_clf = SVC(probability=True, random_state=42)\ndecision_tree_clf = DecisionTreeClassifier(random_state=42)\nbagged_tree_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=42)\nxgb_clf = XGBClassifier(random_state=42) \n\n# Created the voting classifier using multiple base classifiers\nvoting_clf = VotingClassifier(\n    estimators=[\n        ('rf', random_forest_clf),\n        ('gb', gradient_boosting_clf),\n        ('ab', ada_boost_clf),\n        ('svc', svc_clf),\n        ('dt', decision_tree_clf),\n        ('bt', bagged_tree_clf),\n        ('xgb', xgb_clf)\n    ],\n    voting='soft'  # Used 'soft' for probability-based voting\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.152921Z","iopub.execute_input":"2023-10-04T08:48:21.153441Z","iopub.status.idle":"2023-10-04T08:48:21.166372Z","shell.execute_reply.started":"2023-10-04T08:48:21.153408Z","shell.execute_reply":"2023-10-04T08:48:21.165167Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Trained the voting classifier on the training data\nvoting_clf.fit(x_train, y_train)\n\n# Made predictions on the test data\ny_pred = voting_clf.predict(x_test)\n\n# Imported the classification_report function from sklearn.metrics\n\n# Calculated the classification report to evaluate the model's performance\nreport = classification_report(y_test, y_pred)\n\n# Printed the classification report to assess model performance\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.168257Z","iopub.execute_input":"2023-10-04T08:48:21.168915Z","iopub.status.idle":"2023-10-04T08:48:21.963236Z","shell.execute_reply.started":"2023-10-04T08:48:21.168884Z","shell.execute_reply":"2023-10-04T08:48:21.962354Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.80      0.87      0.84       157\n           1       0.79      0.69      0.74       111\n\n    accuracy                           0.80       268\n   macro avg       0.80      0.78      0.79       268\nweighted avg       0.80      0.80      0.80       268\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Imported the accuracy_score function from sklearn.metrics\n\n# Calculated the accuracy of the model's predictions\naccuracy = accuracy_score(y_test, y_pred)\n\n# Printed the accuracy score with two decimal places\nprint(f'Accuracy: {accuracy:.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.964209Z","iopub.execute_input":"2023-10-04T08:48:21.964898Z","iopub.status.idle":"2023-10-04T08:48:21.972264Z","shell.execute_reply.started":"2023-10-04T08:48:21.964871Z","shell.execute_reply":"2023-10-04T08:48:21.971195Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Accuracy: 0.80\n","output_type":"stream"}]},{"cell_type":"code","source":"# Imported the pandas library and read the test dataset from a CSV file\nfd = pd.read_csv('/kaggle/input/titanic/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.973484Z","iopub.execute_input":"2023-10-04T08:48:21.973782Z","iopub.status.idle":"2023-10-04T08:48:21.992830Z","shell.execute_reply.started":"2023-10-04T08:48:21.973758Z","shell.execute_reply":"2023-10-04T08:48:21.991629Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"fd","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:21.999585Z","iopub.execute_input":"2023-10-04T08:48:22.000739Z","iopub.status.idle":"2023-10-04T08:48:22.021093Z","shell.execute_reply.started":"2023-10-04T08:48:22.000689Z","shell.execute_reply":"2023-10-04T08:48:22.019712Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Pclass                                          Name  \\\n0            892       3                              Kelly, Mr. James   \n1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n2            894       2                     Myles, Mr. Thomas Francis   \n3            895       3                              Wirz, Mr. Albert   \n4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n..           ...     ...                                           ...   \n413         1305       3                            Spector, Mr. Woolf   \n414         1306       1                  Oliva y Ocana, Dona. Fermina   \n415         1307       3                  Saether, Mr. Simon Sivertsen   \n416         1308       3                           Ware, Mr. Frederick   \n417         1309       3                      Peter, Master. Michael J   \n\n        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n0      male  34.5      0      0              330911    7.8292   NaN        Q  \n1    female  47.0      1      0              363272    7.0000   NaN        S  \n2      male  62.0      0      0              240276    9.6875   NaN        Q  \n3      male  27.0      0      0              315154    8.6625   NaN        S  \n4    female  22.0      1      1             3101298   12.2875   NaN        S  \n..      ...   ...    ...    ...                 ...       ...   ...      ...  \n413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n416    male   NaN      0      0              359309    8.0500   NaN        S  \n417    male   NaN      1      1                2668   22.3583   NaN        C  \n\n[418 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>3</td>\n      <td>Spector, Mr. Woolf</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A.5. 3236</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n      <td>Oliva y Ocana, Dona. Fermina</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17758</td>\n      <td>108.9000</td>\n      <td>C105</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>3</td>\n      <td>Saether, Mr. Simon Sivertsen</td>\n      <td>male</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>3</td>\n      <td>Ware, Mr. Frederick</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>359309</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>3</td>\n      <td>Peter, Master. Michael J</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2668</td>\n      <td>22.3583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Applied the same transformations as above","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = fd.drop(columns=['Name', 'Ticket','PassengerId'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.022328Z","iopub.execute_input":"2023-10-04T08:48:22.022633Z","iopub.status.idle":"2023-10-04T08:48:22.032502Z","shell.execute_reply.started":"2023-10-04T08:48:22.022608Z","shell.execute_reply":"2023-10-04T08:48:22.031534Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df1['FamilySize'] = df1['SibSp'] + df1['Parch']\n\ndf1 = df1.drop(columns=['SibSp', 'Parch'])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.033558Z","iopub.execute_input":"2023-10-04T08:48:22.034578Z","iopub.status.idle":"2023-10-04T08:48:22.045686Z","shell.execute_reply.started":"2023-10-04T08:48:22.034544Z","shell.execute_reply":"2023-10-04T08:48:22.044382Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n\ndf1['Cabin'] =df1['Cabin'].fillna(\"U0\")\ndf1['Deck'] = df1['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\ndf1['Deck'] = df1['Deck'].map(deck)\ndf1['Deck'] = df1['Deck'].fillna(0)\ndf1['Deck'] = df1['Deck'].astype(int)\n# we can now drop the cabin feature\ndf1 = df1.drop(columns=['Cabin'])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.046993Z","iopub.execute_input":"2023-10-04T08:48:22.047668Z","iopub.status.idle":"2023-10-04T08:48:22.061307Z","shell.execute_reply.started":"2023-10-04T08:48:22.047633Z","shell.execute_reply":"2023-10-04T08:48:22.060085Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.062933Z","iopub.execute_input":"2023-10-04T08:48:22.063311Z","iopub.status.idle":"2023-10-04T08:48:22.090416Z","shell.execute_reply.started":"2023-10-04T08:48:22.063281Z","shell.execute_reply":"2023-10-04T08:48:22.089473Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"     Pclass     Sex   Age      Fare Embarked  FamilySize  Deck\n0         3    male  34.5    7.8292        Q           0     8\n1         3  female  47.0    7.0000        S           1     8\n2         2    male  62.0    9.6875        Q           0     8\n3         3    male  27.0    8.6625        S           0     8\n4         3  female  22.0   12.2875        S           2     8\n..      ...     ...   ...       ...      ...         ...   ...\n413       3    male   NaN    8.0500        S           0     8\n414       1  female  39.0  108.9000        C           0     3\n415       3    male  38.5    7.2500        S           0     8\n416       3    male   NaN    8.0500        S           0     8\n417       3    male   NaN   22.3583        C           2     8\n\n[418 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>Deck</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>7.8292</td>\n      <td>Q</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>7.0000</td>\n      <td>S</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>9.6875</td>\n      <td>Q</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>8.6625</td>\n      <td>S</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>12.2875</td>\n      <td>S</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>3</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>108.9000</td>\n      <td>C</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>3</td>\n      <td>male</td>\n      <td>38.5</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>3</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>3</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>22.3583</td>\n      <td>C</td>\n      <td>2</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X1 = preprocessor.transform(df1[features])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.091737Z","iopub.execute_input":"2023-10-04T08:48:22.092198Z","iopub.status.idle":"2023-10-04T08:48:22.107144Z","shell.execute_reply.started":"2023-10-04T08:48:22.092156Z","shell.execute_reply":"2023-10-04T08:48:22.105701Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Used the trained voting classifier to make predictions on new data 'X1'\ntestans = voting_clf.predict(X1.toarray())","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.108447Z","iopub.execute_input":"2023-10-04T08:48:22.109186Z","iopub.status.idle":"2023-10-04T08:48:22.165923Z","shell.execute_reply.started":"2023-10-04T08:48:22.109142Z","shell.execute_reply":"2023-10-04T08:48:22.164961Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Created a DataFrame 'res' containing 'PassengerId' and 'Survived' columns based on the predictions\nres = pd.DataFrame({'PassengerId': fd['PassengerId'], 'Survived': testans})\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.167246Z","iopub.execute_input":"2023-10-04T08:48:22.168278Z","iopub.status.idle":"2023-10-04T08:48:22.174501Z","shell.execute_reply.started":"2023-10-04T08:48:22.168236Z","shell.execute_reply":"2023-10-04T08:48:22.173465Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"res.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.175766Z","iopub.execute_input":"2023-10-04T08:48:22.176462Z","iopub.status.idle":"2023-10-04T08:48:22.189579Z","shell.execute_reply.started":"2023-10-04T08:48:22.176421Z","shell.execute_reply":"2023-10-04T08:48:22.188467Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(418, 2)"},"metadata":{}}]},{"cell_type":"code","source":"res.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.190871Z","iopub.execute_input":"2023-10-04T08:48:22.191323Z","iopub.status.idle":"2023-10-04T08:48:22.207110Z","shell.execute_reply.started":"2023-10-04T08:48:22.191289Z","shell.execute_reply":"2023-10-04T08:48:22.205646Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"res","metadata":{"execution":{"iopub.status.busy":"2023-10-04T08:48:22.208510Z","iopub.execute_input":"2023-10-04T08:48:22.209632Z","iopub.status.idle":"2023-10-04T08:48:22.222512Z","shell.execute_reply.started":"2023-10-04T08:48:22.209598Z","shell.execute_reply":"2023-10-04T08:48:22.221059Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         0\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         0\n\n[418 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}